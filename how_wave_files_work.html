<!DOCTYPE html>
<html lang="en">
<head>
  <title>WaveFile Gem</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <link href='http://fonts.googleapis.com/css?family=Lato:100,300,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Playfair+Display:400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=PT+Mono">
  <link rel="stylesheet" type="text/css" href="wavefile.css">
</head>
<body>
<div id="header">
  <div id="header-inner">
    <h1><a href="http://wavefilegem.com/">WaveFile Gem</a></h1>
    <ul id="navigation">
      <li><a href="getting_started.html">Getting Started</a></li>
      <li class="last"><a href="documentation.html">Documentation</a></li>
    </ul>
  </div>
</div>
<div class="container">
  <h2>Getting Started</h2>
  <p>If you&rsquo;re just getting started with audio programming, you might want to read up on some of the basics of digital audio first. Check out <a href="http://www.joelstrait.com/blog/2009/10/12/a_digital_audio_primer">this blog post</a> for an introduction.</p>

  <h2>Wave Files Store Audio Data</h2>
  <p>Wave files store audio data, encoded using one of several sample formats. Some sample formats contain raw, uncompressed data, while some formats use some sort of compression. The most common sample format is <em>PCM</em>, which stands for <em>pulse code modulation</em>. This is raw, uncompressed sample data where each sample is an integer.</p>
  <p>Currently, the WaveFile gem supports these sample formats:</p>
  <ul>
    <li>PCM at 8, 16, 24, and 32 bits per sample</li>
    <li>IEEE floating point at 32 or 64 bits per sample</li>
    <li>The formats above inside a WAVE_FORMAT_EXTENSIBLE container</li>
  </ul>

  <h2>Wave Files are RIFF Files</h2>
  <p>Back in the late 80s Electronic Arts came up with a general container file format that could be used to store different types of data &ndash; audio, graphics, etc. It was called <em>IFF</em>, for <em>Interchange File Format</em>. Microsoft then took this format, switched the byte order to <a href="http://en.wikipedia.org/wiki/Endianness">little-endian</a> to match Intel processors, and dubbed it <em>RIFF (Resource Interchange File Format</em>). Many of the venerable Microsoft multimedia file formats are stored as RIFF files, including <code>*.rtf</code> (&ldquo;rich text format&rdquo;, a WYSIWYG text format), <code>*.avi</code> (a basically obsolete movie format), and of course, <code>*.wav</code>.</p>
  <p>As mentioned above, all data in a RIFF file is stored as <a href="http://en.wikipedia.org/wiki/Endianness">little-endian</a>, owing to its Wintel heritage.</p>
  <h2>RIFF Files Contain &ldquo;Chunks&rdquo;</h2>
  <p>An IFF file, and therefore a RIFF file, is broken up into several &ldquo;chunks&rdquo; of data. Each chunk has an 8-byte header containing a 4-byte identifier code, and a 4-byte size field.</p>
  <p>The identifier code, called a <a href="http://en.wikipedia.org/wiki/Fourcc">FourCC</a>, is typically a more-or-less human-readable ASCII string. For example, <code>"wave"</code>, <code>"fmt&nbsp;"</code>, or <code>"data"</code>. This identifier is case-sensitive.</p>
  <p>The size field indicates the size of the chunk in bytes. The size does not include the 8-bytes in the header. I.e., if a chunk consists of the header plus 1,000 bytes of data, the size field will indicate 1,000, not 1,008. Chunks can internally contain nested sub-chunks, if the spec for that chunk allows it.</p>
  <p><span class="tag-important">Important!</span>If a chunk body is an odd number of bytes, it must be followed by an empty padding byte. In other words, a chunk must always occupy an even number of bytes in the file. The padding byte is <em>not</em> counted in the chunk size field. For example, if a chunk body is 17 bytes in size, the size ID field will be set to 17, but the actual chunk body will occupy 18 bytes (17 bytes of data followed by a padding byte).</p>
  <h2>High Level Wave File Structure</h2>
  <p>At top level, a Wave file consists of a single <code>"RIFF"</code> chunk, which contains all of the data for the wave file. The RIFF chunk body starts with a format code <code>"WAVE"</code> which indicates that the sub-chunks are for a Wave file. (As opposed to a rich text file, bitmap, etc). This is followed by the sub chunks. A Wave file is required to contain at minimum a format chunk and a data chunk (described below), and the format chunk must come before the data chunk. If the format code in the format chunk is not 1 (see below), then it must also contain a <code>"fact"</code> chunk. It can also contain other optional chunks.</p>
  <p>Visually this is what it looks like:</p>
  <div style="border: 2px solid black; padding: 0.75rem 0.75rem 0 0.75rem; max-width: 15.0rem; margin: 0 auto; border-radius: 0.75rem;">
    RIFF Chunk<br />
    Format: <code>"WAVE"</code>
    <div style="border: 2px solid black; padding: 0.75rem; margin: 0.75rem 0; border-radius: 0.75rem;">Format Chunk (<code>"fmt&nbsp;"</code>)</div>
    <div style="border: 2px solid black; padding: 0.75rem; margin: 0.75rem 0; border-radius: 0.75rem;"><em>other optional chunk</em></div>
    <div style="border: 2px solid black; padding: 0.75rem; margin: 0.75rem 0; border-radius: 0.75rem;"><em>other optional chunk</em></div>
    <div style="border: 2px solid black; padding: 0.75rem; margin: 0.75rem 0; border-radius: 0.75rem;">Data Chunk (<code>"data"</code>)</div>
  </div>
  <p><span class="tag-important">Important!</span>Other than the format chunk coming before the data chunk, there isn&rsquo;t any requirement that the chunks come in any particular order. You shouldn&rsquo;t assume that the data chunk is the last chunk. (Although in practice, it usually is).</p>
  <h2>The RIFF Chunk</h2>
  <p>Like all chunks, the RIFF chunk starts with an ID code, in this case the ASCII string <code>"RIFF"</code>. Next is the size field, which is the size of the entire Wave file except for the 8-byte RIFF header.</p>
  <p>The first 4 bytes following the header will identify the type of RIFF chunk. In the case of Wave files, it will be <code>"WAVE"</code>. Immediately following that will be the inner Wave file chunks.</p>
  <table>
    <tr>
      <th>Field</th>
      <th>Size in Bytes</th>
      <th>Description</th>
    </tr>
    <tr>
      <td>Chunk ID</td>
      <td>4</td>
      <td>ASCII string <code>"RIFF"</code></td>
    </tr>
    <tr>
      <td>Chunk Size</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>RIFF Format Code</td>
      <td>4</td>
      <td>ASCII string <code>"WAVE"</code></td>
    </tr>
    <tr>
      <td>Sub Chunks</td>
      <td>Variable</td>
      <td>Variable</td>
    </tr>
  </table>

  <h2>The Format Chunk</h2>
  <p>The format chunk describes the format that the samples in the data chunk are encoded in. The exact structure of the format chunk depends on the value of the format code field. If the format code is 1 (PCM), then the format chunk will only contain the fields above the dashed line in the diagram below. If it's not 1, the chunk will also contain the fields after the dashed line.</p>
  <p>The reason for these differences is that the Wave format is a container for many different kinds of sample formats, and because the Wave format has evolved over time to support new formats. Extra fields that are needed for one sample format might not be needed for another sample format. This also allows new fields to be added without having to change pre-existing Wave files.</p>
  <table>
    <tr>
      <th>Field</th>
      <th>Size in Bytes</th>
      <th>Description</th>
    </tr>
    <tr>
      <td>Chunk ID</td>
      <td>4</td>
      <td>ASCII string <code>"fmt&nbsp;"</code> (note the space after &lsquo;t&rsquo;)</td>
    </tr>
    <tr>
      <td>Chunk Size</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Format Code</td>
      <td>2</td>
      <td>16-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Number of Channels</td>
      <td>2</td>
      <td>16-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Samples per second</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Bytes per Second</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Bytes per Sample Frame<br />(a.k.a block align)</td>
      <td>2</td>
      <td>16-bit unsigned integer</td>
    </tr>
    <tr style="border-bottom: 2px #ddd dashed;">
      <td>Bits per sample</td>
      <td>2</td>
      <td>16-bit unsigned integer</td>
    </tr>
    <tr>
      <td colspan="3"><em>These fields are only present if format code is not 1:</em></td>
    </tr>
    <tr>
      <td>Extension Size</td>
      <td>2</td>
      <td>16-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Extra fields</td>
      <td>Variable</td>
      <td>It depends on the format code</td>
    </tr>
  </table>
  <p>While some of these fields have a large range of possible values, in practice there are only a few that will actually be used. For some background on what some of this terminology means, check out <a href="http://www.joelstrait.com/blog/2009/10/12/a_digital_audio_primer">this blog post</a>.</p>
  <p><span class="label">Format Code</span> &ndash; Indicates how the sample data for the wave file is stored. The most common format is PCM, which has a code of 1. Other formats include IEEE floating point (3), ADPCM (2), &mu;-law (7), and WaveFormatExtensible (65534).</p>
  <p><span class="label">Number of channels</span> &ndash; Typically a file will have 1 channel (mono) or 2 channels (stereo). A surround sound file will have 6* channels. Although this field technically allows you to have up to 65,535 channels, for audio data that would be flat out ridiculous. You would only hear all of the channels if you had 65,535 different speakers, and since a chunk can only hold 4GB of data (due to the 32-bit size field), you would only be able to store about a second and a half** of 8-bit PCM data.</p>
  <p><span class="label">Sample rate</span> &ndash; The number of sample frames that occur each second. A typical value would be 44,100, which is the same as an audio CD.</p>
  <p><span class="label">Bytes per second (byte rate)</span> &ndash; The spec calls this <em>byte rate</em>, which means the number of bytes required for one second of audio data. This is equal to the bytes per sample frame times the sample rate. So with a bytes per sample frame of 32, and a sample rate of 44,100, this should equal 1,411,200.</p>
  <p><span class="label">Bytes per sample frame</span> &ndash; Called <em>block align</em> by the spec, this is the number of bytes required to store a single sample frame, i.e. a single sample for each channel. (Sometimes a sample frame is also referred to as a <em>block</em>). It should be equal to the number of channels times the bits per sample rounded up to a multiple of 8. For example:
      <table>
        <tr>
          <th>Channels</th>
          <th>Bits Per Sample</th>
          <th>Bytes per sample frame</th>
        </tr>
        <tr>
          <td>1</td>
          <td>8</td>
          <td>8</td>
        </tr>
        <tr>
          <td>2</td>
          <td>8</td>
          <td>16</td>
        </tr>
        <tr>
          <td>1</td>
          <td>16</td>
          <td>16</td>
        </tr>
        <tr>
          <td>2</td>
          <td>16</td>
          <td>32</td>
        </tr>
        <tr>
          <td>6</td>
          <td>32</td>
          <td>192</td>
        </tr>
      </table>
  <p>This field can be used to calculate the bytes per second field. Another possible use is for seeking around in a file. For example, if the bytes per sample frame is 32, then to seek forward 10 sample frames you need to seek forward 320 bytes.</p>
  <p>For PCM data, this field is essentially redundant since it can be calculated from the other fields. However, be sure to note the point of rounding bits per sample values to the nearest multiple of 8.</p>
  <p><span class="label">Bits per sample</span> &ndash; For PCM data, typical values will be 8, 16, or 32. If the sample format doesn't require this field, it should be set to 0.</p>
  <p><span class="label">Extension Size</span> &ndash; This field should only be present if the format code is not 1. This indicates the size of the extra fields in bytes. It does not include the bytes in this field itself. If the given sample format has no extra fields, then this field should be set to 0.</p>
  <p><span class="label">Extra Fields</span> &ndash; It depends on the format code! The next sections describe the extra fields for a few audio formats.</p>

  <h2>Extra Format Fields for Floating Point</h2>
  <p>If the format code is 3, then the sample data is stored as floating point numbers. There are no extra fields for this format, so the extension size field should be set to 0.</p>

  <h2>Extra Format Fields for WAVE_FORMAT_EXTENSIBLE</h2>
  <p>If the format code is 65534, then the format is called &ldquo;WAVE_FORMAT_EXTENSIBLE***&rdquo;. This comes from the name of a data structure given to this format in the Windows API. The extensible format is essentially a container format inside another container format. The reason it exists is to work around some ambiguities in the original Wave file format without having to modify existing files.</p>
  <table>
    <tr>
      <th>Field</th>
      <th>Size in Bytes</th>
      <th>Description</th>
    </tr>
    <tr>
      <td>Valid Bits Per Sample</td>
      <td>2</td>
      <td>16-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Channel Mask</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Sub Format</td>
      <td>16</td>
      <td>16-byte GUID</td>
    </tr>
  </table>
  <p>If format does not meet the criteria below, then the extension size field should be present:</p>
  <ul>
    <li>Sample format is PCM (i.e. 1)</li>
    <li>Number of channels is 1 or 2</li>
    <li>Bits per sample is 8 or 16</li>
  </ul>
  <p>When the format is WaveFormatExtensible, the extension size should be 22, and the remaining three fields should be included:</p>
  <p><span class="label">Valid Bits Per Sample</span> &ndash; TODO</p>
  <p><span class="label">Channel Mask</span> &ndash; Indicates which audio channels map to which speakers.</p>
  <p><span class="label">Sub Format</span> &ndash; Identifies the format of the sample data in the data chunk. This is a replacement for the original format code field, since it will have a format code of 65534.</p>

  <h2>The Fact Chunk</h2>
  <table>
    <tr>
      <th>Field</th>
      <th>Size in Bytes</th>
      <th>Description</th>
    </tr>
    <tr>
      <td>Chunk ID</td>
      <td>4</td>
      <td>ASCII string <code>"fact"</code></td>
    </tr>
    <tr>
      <td>Chunk Size</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Number of sample frames</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
  </table>
  <p>The fact chunk indicates how many sample frames are in the file. It&rsquo;s required if the format code in the format chunk is not 1. If the format code is 1, it&rsquo;s optional. The reason for this chunk is that with some sample formats the number of sample frames can&rsquo;t be determined by obvious means (e.g. because they store data in a compressed format). This gives a way of determining e.g. the playing time for the file, without having to decode the entire data chunk.</p>

  <h2>The Data Chunk</h2>
  <table>
    <tr>
      <th>Field</th>
      <th>Size in Bytes</th>
      <th>Description</th>
    </tr>
    <tr>
      <td>Chunk ID</td>
      <td>4</td>
      <td>ASCII string <code>"data"</code></td>
    </tr>
    <tr>
      <td>Chunk Size</td>
      <td>4</td>
      <td>32-bit unsigned integer</td>
    </tr>
    <tr>
      <td>Sample Data</td>
      <td>Various</td>
      <td>It depends on the format code</td>
    </tr>
  </table>
  <p>The layout for the data chunk is simpler than the format chunk: the normal 8-byte chunk header, followed by nothing but sweet, raw, unfiltered sample data. The sample data can be stored in a number of formats, which will be indicated by the format chunk.</p>
  <p>The next several sections describe various formats that data in the data chunk can be stored as.</p>

  <h2>PCM Data Chunk</h2>
  <p>The simplest, and most common, is to store PCM samples (format code 1). This is just raw sample data stored as integers. The bits per sample field will indicate the range of the sample data:</p>
  <table>
    <tr>
      <th>Bits per sample</th>
      <th>Minimum Sample</th>
      <th>Maximum Sample</th>
    </tr>
    <tr>
      <td>8</td>
      <td>0</td>
      <td>255</td>
    </tr>
    <tr>
      <td>16</td>
      <td>-32,768</td>
      <td>32,767</td>
    </tr>
    <tr>
      <td>24</td>
      <td>-8,388,608</td>
      <td>8,388,607</td>
    </tr>
    <tr>
      <td>32</td>
      <td>-2,147,483,648</td>
      <td>2,147,483,647</td>
    </tr>
  </table>
  <p><span class="tag-important">Important!</span>Notice that 8-bit samples are unsigned, while larger bit depths are signed.</p>
  <p>Samples in a multi-channel PCM wave file are interleaved. That is, in a stereo file, one sample for the left channel will be followed by one sample for the right channel, followed by another sample for the left channel, then right channel, and so forth.</p>
  <p>The samples for all channels at a moment in time are called a <em>sample frame</em> (also called a <em>block</em>). That is, a sample frame will contain one sample for each channel. In a monophonic file, a sample frame will consist on 1 sample. In a stereo file, a sample frame has 2 samples (one for the left channel, one for the right channel). In a 5-channel file, a sample frame has 5 samples. The block align field in the format chunk gives the size in bytes of each sample frame. This can be useful when seeking to a particular sample frame in the file.</p>
  <h2>Floating Point Data Chunk</h2>
  <p>Another basic format is to store samples as floating point values (format code 3). This is essentially the same as PCM format, except that samples are in the range -1.0 to 1.0. The bits per sample field for floating point files should be set to 32 or 64.</p>
  <h2>WAVE_FORMAT_EXTENSIBLE Data Chunk</h2>
  <p>Since WAVE_FORMAT_EXTENSIBLE is a container format, the format code of 65534 doesn't imply any particular sample format. The sample format is instead determined by the sub format GUID in the format chunk. For example, if the sub format GUID is the GUID for PCM, then the samples are in the same format as if the format code was 1.</p>

  <h2>References</h2>
  <p>Documents from Microsoft defining the initial file format, and changes over time:</p>
  <ul>
    <li><a href="http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/Docs/riffmci.pdf">Multimedia Programming Interface
and Data Specifications 1.0, August 1991</a></li>
    <li><a href="http://download.microsoft.com/download/9/8/6/9863C72A-A3AA-4DDB-B1BA-CA8D17EFD2D4/RIFFNEW.pdf">New Multimedia Data Types and Data Techniques, August 1994</a></li>
    <li><a href="http://msdn.microsoft.com/en-us/library/windows/hardware/gg463006.aspx">Multiple Channel Audio Data and WAVE Files</a></li>
  </ul>
  <p>Other links:</p>
  <ul>
    <li><a href="http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/WAVE.html">Helpful summary from McGill University that has similar content as this page</a></li>
    <li><a href="http://en.wikipedia.org/wiki/WAV">Wikipedia article on the *.wav format</a></li>
  </ul>
</div>
<div class="footer">
  <p>View the source on <a href="https://github.com/jstrait/wavefile/">GitHub</a>.</p>
  <p>Copyright &copy; <a href="http://www.joelstrait.com">Joel Strait</a> 2009-17.</p>
</div>
</body>
</html>
